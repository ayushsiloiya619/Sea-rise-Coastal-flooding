{
 "cells": [
  {
   "cell_type": "code",
 
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 400 Client Error:  for url: https://YOUR-OWN-URL"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Disable SSL certificate verification warning\n",
    "requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)\n",
    "\n",
    "# Set your NOAA API token\n",
    "api_token = \"YOUR-TOKEN\"\n",
    "\n",
    "# Set the base URL for station queries\n",
    "base_url = \"https://YOUR-URL",
    "\n",
    "# Set the request headers with the API token\n",
    "headers = {\"Token\": api_token}\n",
    "\n",
    "try:\n",
    "    # Fetch all available stations\n",
    "    all_stations_url = base_url\n",
    "    all_stations_response = requests.get(all_stations_url, headers=headers)\n",
    "    all_stations_data = all_stations_response.json()\n",
    "\n",
    "    # Fetch information about a specific station (e.g., Abbeville AL)\n",
    "    specific_station_url = f\"{base_url}/COOP:010008\"\n",
    "    specific_station_response = requests.get(specific_station_url, headers=headers)\n",
    "    specific_station_data = specific_station_response.json()\n",
    "\n",
    "    # Fetch stations in North Carolina, US (FIPS:37)\n",
    "    nc_stations_url = f\"{base_url}?locationid=FIPS:37\"\n",
    "    nc_stations_response = requests.get(nc_stations_url, headers=headers)\n",
    "    nc_stations_data = nc_stations_response.json()\n",
    "\n",
    "    # Fetch stations supporting a given set of data types (e.g., EMNT, EMXT, HTMN)\n",
    "    data_types = [\"EMNT\", \"EMXT\", \"HTMN\"]\n",
    "    data_types_url = f\"{base_url}?datatypeid={','.join(data_types)}\"\n",
    "    data_types_response = requests.get(data_types_url, headers=headers)\n",
    "    data_types_stations_data = data_types_response.json()\n",
    "\n",
    "    # Process and display the fetched data\n",
    "    print(\"All Stations:\")\n",
    "    print(all_stations_data)\n",
    "\n",
    "    print(\"\\nSpecific Station (Abbeville AL):\")\n",
    "    print(specific_station_data)\n",
    "\n",
    "    print(\"\\nStations in North Carolina:\")\n",
    "    print(nc_stations_data)\n",
    "\n",
    "    print(\"\\nStations supporting given data types:\")\n",
    "    print(data_types_stations_data)\n",
    "\n",
    "    # Set the API endpoint URLs for sea level rise and coastal flooding\n",
    "    sea_level_rise_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=SEA_LEVEL&stationid=STATION_ID\"\n",
    "    coastal_flooding_url = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data?datasetid=COASTAL_FLOODING&stationid=STATION_ID\"\n",
    "\n",
    "    # Set the station IDs for sea level rise and coastal flooding\n",
    "    sea_level_rise_station_id = \"STATION_ID\"\n",
    "    coastal_flooding_station_id = \"STATION_ID\"\n",
    "\n",
    "    # Fetch sea level rise data\n",
    "    sea_level_rise_url = sea_level_rise_url.replace(\"STATION_ID\", sea_level_rise_station_id)\n",
    "    sea_level_rise_response = requests.get(sea_level_rise_url, headers=headers, verify=False)\n",
    "    sea_level_rise_response.raise_for_status()\n",
    "    sea_level_rise_data = sea_level_rise_response.json()\n",
    "\n",
    "    # Fetch coastal flooding data\n",
    "    coastal_flooding_url = coastal_flooding_url.replace(\"STATION_ID\", coastal_flooding_station_id)\n",
    "    coastal_flooding_response = requests.get(coastal_flooding_url, headers=headers, verify=False)\n",
    "    coastal_flooding_response.raise_for_status()\n",
    "    coastal_flooding_data = coastal_flooding_response.json()\n",
    "\n",
    "    # Process and display sea level rise data\n",
    "    print(\"\\nSea Level Rise Data:\")\n",
    "    for result in sea_level_rise_data[\"results\"]:\n",
    "        print(f\"Date: {result['date']}, Sea Level: {result['value']}\")\n",
    "\n",
    "    # Process and display coastal flooding data\n",
    "    print(\"\\nCoastal Flooding Data:\")\n",
    "    for result in coastal_flooding_data[\"results\"]:\n",
    "        print(f\"Date: {result['date']}, Flooding Risk: {result['value']}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "712e30b9",
   "metadata": {},
   "outputs": [
    {
   
   "source": [
    "import requests\n",
    "\n",
    "# Set your NOAA API token\n",
    "api_token = \"YOUR-OWN"\n",
    "\n",
    "# Set the base URL for station queries\n",
    "base_url = \"YOUR-OWN",
    "\n",
    "# Set the request headers with the API token\n",
    "headers = {\"Token\": api_token}\n",
    "\n",
    "try:\n",
    "    # Fetch all available stations\n",
    "    all_stations_url = base_url\n",
    "    all_stations_response = requests.get(all_stations_url, headers=headers)\n",
    "    all_stations_data = all_stations_response.json()\n",
    "\n",
    "    # Process and display all stations\n",
    "    print(\"All Stations:\")\n",
    "    print(all_stations_data)\n",
    "\n",
    "    # Extract the station ID for sea level rise and coastal flooding\n",
    "    sea_level_rise_station_id = \"COOP:010008\"\n",
    "\n",
    "    # Set the API endpoint URL for sea level rise\n",
    "    sea_level_rise_url = f\"{base_url}/{sea_level_rise_station_id}\"\n",
    "\n",
    "    # Fetch sea level rise data\n",
    "    sea_level_rise_response = requests.get(sea_level_rise_url, headers=headers)\n",
    "    sea_level_rise_data = sea_level_rise_response.json()\n",
    "\n",
    "    # Process and display sea level rise data\n",
    "    print(\"\\nSea Level Rise Data:\")\n",
    "    print(sea_level_rise_data)\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ede5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Stations:\n",
      "{'metadata': {'resultset': {'offset': 1, 'count': 148703, 'limit': 25}}, 'results': [{'elevation': 139, 'mindate': '1948-01-01', 'maxdate': '2014-01-01', 'latitude': 31.5702, 'name': 'ABBEVILLE, AL US', 'datacoverage': 0.8813, 'id': 'COOP:010008', 'elevationUnit': 'METERS', 'longitude': -85.2482}, {'elevation': 239.6, 'mindate': '1938-01-01', 'maxdate': '2015-11-01', 'latitude': 34.21096, 'name': 'ADDISON, AL US', 'datacoverage': 0.5059, 'id': 'COOP:010063', 'elevationUnit': 'METERS', 'longitude': -87.17838}, {'elevation': 302.1, 'mindate': '1940-05-01', 'maxdate': '1962-03-01', 'latitude': 34.41667, 'name': 'ADDISON CENTRAL TOWER, AL US', 'datacoverage': 0.9658, 'id': 'COOP:010071', 'elevationUnit': 'METERS', 'longitude': -87.31667}, {'elevation': 172.5, 'mindate': '1995-04-01', 'maxdate': '2015-11-01', 'latitude': 33.17835, 'name': 'ALABASTER SHELBY CO AIRPORT ASOS, AL US', 'datacoverage': 0.8064, 'id': 'COOP:010116', 'elevationUnit': 'METERS', 'longitude': -86.78178}, {'elevation': 183.8, 'mindate': '1949-01-01', 'maxdate': '1949-12-01', 'latitude': 34.6891, 'name': 'BELLE MINA 2 N, AL US', 'datacoverage': 1, 'id': 'COOP:010117', 'elevationUnit': 'METERS', 'longitude': -86.8819}, {'elevation': 34.1, 'mindate': '1935-05-01', 'maxdate': '1936-11-01', 'latitude': 31.13333, 'name': 'ALAGA, AL US', 'datacoverage': 0.2624, 'id': 'COOP:010125', 'elevationUnit': 'METERS', 'longitude': -85.06667}, {'elevation': 53.3, 'mindate': '1940-11-01', 'maxdate': '2014-12-01', 'latitude': 32.2322, 'name': 'ALBERTA, AL US', 'datacoverage': 0.9888, 'id': 'COOP:010140', 'elevationUnit': 'METERS', 'longitude': -87.4104}, {'elevation': 348.1, 'mindate': '1931-01-01', 'maxdate': '1977-06-01', 'latitude': 34.23333, 'name': 'ALBERTVILLE, AL US', 'datacoverage': 0.9535, 'id': 'COOP:010148', 'elevationUnit': 'METERS', 'longitude': -86.16667}, {'elevation': 201.2, 'mindate': '1969-10-01', 'maxdate': '2015-11-01', 'latitude': 32.935, 'name': 'ALEXANDER CITY, AL US', 'datacoverage': 0.9946, 'id': 'COOP:010160', 'elevationUnit': 'METERS', 'longitude': -85.95556}, {'elevation': 200.9, 'mindate': '1942-11-01', 'maxdate': '1969-10-01', 'latitude': 32.98333, 'name': 'ALEXANDER CITY 6 NE, AL US', 'datacoverage': 0.9629, 'id': 'COOP:010163', 'elevationUnit': 'METERS', 'longitude': -85.86667}, {'elevation': 59.4, 'mindate': '1940-01-01', 'maxdate': '2015-11-01', 'latitude': 33.1272, 'name': 'ALICEVILLE, AL US', 'datacoverage': 0.9144, 'id': 'COOP:010178', 'elevationUnit': 'METERS', 'longitude': -88.155}, {'elevation': 50.3, 'mindate': '1980-05-01', 'maxdate': '2015-11-01', 'latitude': 33.21, 'name': 'BEVILL LOCK AND DAM, AL US', 'datacoverage': 0.9883, 'id': 'COOP:010184', 'elevationUnit': 'METERS', 'longitude': -88.2878}, {'elevation': 76.2, 'mindate': '1938-01-01', 'maxdate': '2015-11-01', 'latitude': 31.3071, 'name': 'ANDALUSIA 3 W, AL US', 'datacoverage': 0.9744, 'id': 'COOP:010252', 'elevationUnit': 'METERS', 'longitude': -86.5226}, {'elevation': 231.6, 'mindate': '2004-07-01', 'maxdate': '2015-11-01', 'latitude': 34.96285, 'name': 'LEXINGTON, AL US', 'datacoverage': 1, 'id': 'COOP:010260', 'elevationUnit': 'METERS', 'longitude': -87.37195}, {'elevation': 220.1, 'mindate': '1948-01-01', 'maxdate': '1949-03-01', 'latitude': 33.66667, 'name': 'ANNISTON, AL US', 'datacoverage': 1, 'id': 'COOP:010267', 'elevationUnit': 'METERS', 'longitude': -85.83333}, {'elevation': 181.8, 'mindate': '1948-01-01', 'maxdate': '2015-11-01', 'latitude': 33.59043, 'name': 'ANNISTON METROPOLITAN AIRPORT, AL US', 'datacoverage': 0.9816, 'id': 'COOP:010272', 'elevationUnit': 'METERS', 'longitude': -85.84788}, {'elevation': 227.1, 'mindate': '1938-01-01', 'maxdate': '1983-10-01', 'latitude': 34.06667, 'name': 'ARLEY 1 S, AL US', 'datacoverage': 0.9691, 'id': 'COOP:010338', 'elevationUnit': 'METERS', 'longitude': -87.23333}, {'elevation': 311.5, 'mindate': '1948-01-01', 'maxdate': '2013-11-01', 'latitude': 33.2941, 'name': 'ASHLAND, AL US', 'datacoverage': 0.8872, 'id': 'COOP:010369', 'elevationUnit': 'METERS', 'longitude': -85.7788}, {'elevation': 180.1, 'mindate': '1941-06-01', 'maxdate': '1973-06-01', 'latitude': 33.85, 'name': 'ASHVILLE, AL US', 'datacoverage': 0.9429, 'id': 'COOP:010377', 'elevationUnit': 'METERS', 'longitude': -86.33333}, {'elevation': 210, 'mindate': '1948-01-01', 'maxdate': '2015-11-01', 'latitude': 34.7752, 'name': 'ATHENS, AL US', 'datacoverage': 0.5632, 'id': 'COOP:010390', 'elevationUnit': 'METERS', 'longitude': -86.9508}, {'elevation': 219.5, 'mindate': '1955-10-01', 'maxdate': '1991-07-01', 'latitude': 34.8, 'name': 'ATHENS 2, AL US', 'datacoverage': 0.9442, 'id': 'COOP:010395', 'elevationUnit': 'METERS', 'longitude': -86.98333}, {'elevation': 220.1, 'mindate': '1958-05-01', 'maxdate': '1958-06-01', 'latitude': 34.8, 'name': 'ATHENS COURTHOUSE, AL US', 'datacoverage': 0.998, 'id': 'COOP:010398', 'elevationUnit': 'METERS', 'longitude': -86.96667}, {'elevation': 91.4, 'mindate': '1940-01-01', 'maxdate': '2015-11-01', 'latitude': 31.182, 'name': 'ATMORE, AL US', 'datacoverage': 0.7103, 'id': 'COOP:010402', 'elevationUnit': 'METERS', 'longitude': -87.439}, {'elevation': 67.1, 'mindate': '1965-01-01', 'maxdate': '1982-10-01', 'latitude': 31.01667, 'name': 'ATMORE, AL US', 'datacoverage': 0.967, 'id': 'COOP:010407', 'elevationUnit': 'METERS', 'longitude': -87.51667}, {'elevation': 223.1, 'mindate': '1931-01-01', 'maxdate': '1970-12-01', 'latitude': 32.6, 'name': 'AUBURN, AL US', 'datacoverage': 0.9917, 'id': 'COOP:010422', 'elevationUnit': 'METERS', 'longitude': -85.5}]}\n",
      "\n",
      "Station Data:\n",
      "{'elevation': 139, 'mindate': '1948-01-01', 'maxdate': '2014-01-01', 'latitude': 31.5702, 'name': 'ABBEVILLE, AL US', 'datacoverage': 0.8813, 'id': 'COOP:010008', 'elevationUnit': 'METERS', 'longitude': -85.2482}\n",
      "\n",
      "Specific Data:\n",
      "Elevation: 139\n",
      "Mindate: 1948-01-01\n",
      "Maxdate: 2014-01-01\n",
      "Latitude: 31.5702\n",
      "Name: ABBEVILLE, AL US\n",
      "Datacoverage: 0.8813\n",
      "ID: COOP:010008\n",
      "Elevation Unit: METERS\n",
      "Longitude: -85.2482\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set your NOAA API token\n",
    "api_token = \"YOUR-OWNn",
    "\n",
    "# Set the base URL for station queries\n",
    "base_url = \"YOUR-OWN",
    "\n",
    "# Set the request headers with the API token\n",
    "headers = {\"Token\": api_token}\n",
    "\n",
    "try:\n",
    "    # Fetch all available stations\n",
    "    all_stations_url = base_url\n",
    "    all_stations_response = requests.get(all_stations_url, headers=headers)\n",
    "    all_stations_data = all_stations_response.json()\n",
    "\n",
    "    # Process and display all stations\n",
    "    print(\"All Stations:\")\n",
    "    print(all_stations_data)\n",
    "\n",
    "    # Set the station ID for sea level rise and coastal flooding\n",
    "    station_id = \"COOP:010008\"\n",
    "\n",
    "    # Set the API endpoint URL for sea level rise and coastal flooding\n",
    "    station_url = f\"{base_url}/{station_id}\"\n",
    "\n",
    "    # Fetch sea level rise data\n",
    "    station_response = requests.get(station_url, headers=headers)\n",
    "    station_data = station_response.json()\n",
    "\n",
    "    # Process and display sea level rise data\n",
    "    print(\"\\nStation Data:\")\n",
    "    print(station_data)\n",
    "\n",
    "    # Extract and print specific data fields\n",
    "    elevation = station_data['elevation']\n",
    "    mindate = station_data['mindate']\n",
    "    maxdate = station_data['maxdate']\n",
    "    latitude = station_data['latitude']\n",
    "    name = station_data['name']\n",
    "    datacoverage = station_data['datacoverage']\n",
    "    id = station_data['id']\n",
    "    elevationUnit = station_data['elevationUnit']\n",
    "    longitude = station_data['longitude']\n",
    "\n",
    "    print(\"\\nSpecific Data:\")\n",
    "    print(f\"Elevation: {elevation}\")\n",
    "    print(f\"Mindate: {mindate}\")\n",
    "    print(f\"Maxdate: {maxdate}\")\n",
    "    print(f\"Latitude: {latitude}\")\n",
    "    print(f\"Name: {name}\")\n",
    "    print(f\"Datacoverage: {datacoverage}\")\n",
    "    print(f\"ID: {id}\")\n",
    "    print(f\"Elevation Unit: {elevationUnit}\")\n",
    "    print(f\"Longitude: {longitude}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f35042eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sea Level Rise Data:\n",
      "\n",
      "Sea Level Rise Specific Data:\n",
      "Elevation: 139\n",
      "Mindate: 1948-01-01\n",
      "Maxdate: 2014-01-01\n",
      "Latitude: 31.5702\n",
      "Name: ABBEVILLE, AL US\n",
      "Datacoverage: 0.8813\n",
      "ID: COOP:010008\n",
      "Elevation Unit: METERS\n",
      "Longitude: -85.2482\n",
      "\n",
      "Coastal Flooding Data:\n",
      "\n",
      "Coastal Flooding Specific Data:\n",
      "Elevation: 231.6\n",
      "Mindate: 2004-07-01\n",
      "Maxdate: 2015-11-01\n",
      "Latitude: 34.96285\n",
      "Name: LEXINGTON, AL US\n",
      "Datacoverage: 1\n",
      "ID: COOP:010260\n",
      "Elevation Unit: METERS\n",
      "Longitude: -87.37195\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Set your NOAA API token\n",
    "api_token = \"YOUR-OWN",
    "\n",
    "# Set the base URL for station queries\n",
    "base_url = \"YOUR-OWN",
    "\n",
    "# Set the request headers with the API token\n",
    "headers = {\"Token\": api_token}\n",
    "\n",
    "try:\n",
    "    # Set the station ID for sea level rise and coastal flooding\n",
    "    sea_level_rise_station_id = \"COOP:010008\"\n",
    "    coastal_flooding_station_id = \"COOP:010260\"\n",
    "\n",
    "    # Set the API endpoint URLs for sea level rise and coastal flooding\n",
    "    sea_level_rise_url = f\"{base_url}/{sea_level_rise_station_id}\"\n",
    "    coastal_flooding_url = f\"{base_url}/{coastal_flooding_station_id}\"\n",
    "\n",
    "    # Fetch sea level rise data\n",
    "    sea_level_rise_response = requests.get(sea_level_rise_url, headers=headers)\n",
    "    sea_level_rise_data = sea_level_rise_response.json()\n",
    "\n",
    "    # Extract and print specific data fields for sea level rise\n",
    "    print(\"Sea Level Rise Data:\")\n",
    "    sea_level_rise_elevation = sea_level_rise_data['elevation']\n",
    "    sea_level_rise_mindate = sea_level_rise_data['mindate']\n",
    "    sea_level_rise_maxdate = sea_level_rise_data['maxdate']\n",
    "    sea_level_rise_latitude = sea_level_rise_data['latitude']\n",
    "    sea_level_rise_name = sea_level_rise_data['name']\n",
    "    sea_level_rise_datacoverage = sea_level_rise_data['datacoverage']\n",
    "    sea_level_rise_id = sea_level_rise_data['id']\n",
    "    sea_level_rise_elevationUnit = sea_level_rise_data['elevationUnit']\n",
    "    sea_level_rise_longitude = sea_level_rise_data['longitude']\n",
    "\n",
    "    print(\"\\nSea Level Rise Specific Data:\")\n",
    "    print(f\"Elevation: {sea_level_rise_elevation}\")\n",
    "    print(f\"Mindate: {sea_level_rise_mindate}\")\n",
    "    print(f\"Maxdate: {sea_level_rise_maxdate}\")\n",
    "    print(f\"Latitude: {sea_level_rise_latitude}\")\n",
    "    print(f\"Name: {sea_level_rise_name}\")\n",
    "    print(f\"Datacoverage: {sea_level_rise_datacoverage}\")\n",
    "    print(f\"ID: {sea_level_rise_id}\")\n",
    "    print(f\"Elevation Unit: {sea_level_rise_elevationUnit}\")\n",
    "    print(f\"Longitude: {sea_level_rise_longitude}\")\n",
    "\n",
    "    # Fetch coastal flooding data\n",
    "    coastal_flooding_response = requests.get(coastal_flooding_url, headers=headers)\n",
    "    coastal_flooding_data = coastal_flooding_response.json()\n",
    "\n",
    "    # Extract and print specific data fields for coastal flooding\n",
    "    print(\"\\nCoastal Flooding Data:\")\n",
    "    coastal_flooding_elevation = coastal_flooding_data['elevation']\n",
    "    coastal_flooding_mindate = coastal_flooding_data['mindate']\n",
    "    coastal_flooding_maxdate = coastal_flooding_data['maxdate']\n",
    "    coastal_flooding_latitude = coastal_flooding_data['latitude']\n",
    "    coastal_flooding_name = coastal_flooding_data['name']\n",
    "    coastal_flooding_datacoverage = coastal_flooding_data['datacoverage']\n",
    "    coastal_flooding_id = coastal_flooding_data['id']\n",
    "    coastal_flooding_elevationUnit = coastal_flooding_data['elevationUnit']\n",
    "    coastal_flooding_longitude = coastal_flooding_data['longitude']\n",
    "\n",
    "    print(\"\\nCoastal Flooding Specific Data:\")\n",
    "    print(f\"Elevation: {coastal_flooding_elevation}\")\n",
    "    print(f\"Mindate: {coastal_flooding_mindate}\")\n",
    "    print(f\"Maxdate: {coastal_flooding_maxdate}\")\n",
    "    print(f\"Latitude: {coastal_flooding_latitude}\")\n",
    "    print(f\"Name: {coastal_flooding_name}\")\n",
    "    print(f\"Datacoverage: {coastal_flooding_datacoverage}\")\n",
    "    print(f\"ID: {coastal_flooding_id}\")\n",
    "    print(f\"Elevation Unit: {coastal_flooding_elevationUnit}\")\n",
    "    print(f\"Longitude: {coastal_flooding_longitude}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0969c401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
